{
  "timestamp": "2025-11-22T00:16:50.869218",
  "results": {
    "openai": {
      "provider": "openai",
      "skipped": false,
      "total": 24,
      "valid": 11,
      "results": [
        {
          "provider": "openai",
          "model": "gpt-5",
          "valid": false,
          "status_code": 400,
          "error": "Bad request: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "gpt-5-turbo",
          "valid": false,
          "status_code": 404,
          "error": "Model not found (404)",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "gpt-5-preview",
          "valid": false,
          "status_code": 404,
          "error": "Model not found (404)",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "gpt-5-2025-08-07",
          "valid": false,
          "status_code": 400,
          "error": "Bad request: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "gpt-4o",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-2024-08-06"
        },
        {
          "provider": "openai",
          "model": "gpt-4o-latest",
          "valid": false,
          "status_code": 404,
          "error": "Model not found (404)",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "gpt-4o-2024-11-20",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-2024-11-20"
        },
        {
          "provider": "openai",
          "model": "gpt-4o-2024-08-06",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-2024-08-06"
        },
        {
          "provider": "openai",
          "model": "gpt-4o-mini",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-mini-2024-07-18"
        },
        {
          "provider": "openai",
          "model": "gpt-4o-mini-2024-07-18",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-mini-2024-07-18"
        },
        {
          "provider": "openai",
          "model": "chatgpt-4o-latest",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "chatgpt-4o-latest"
        },
        {
          "provider": "openai",
          "model": "o1",
          "valid": false,
          "status_code": 400,
          "error": "Bad request: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "o1-preview",
          "valid": false,
          "status_code": 404,
          "error": "Model not found (404)",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "o1-preview-2024-09-12",
          "valid": false,
          "status_code": 404,
          "error": "Model not found (404)",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "o1-mini",
          "valid": false,
          "status_code": 404,
          "error": "Model not found (404)",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "o1-mini-2024-09-12",
          "valid": false,
          "status_code": 404,
          "error": "Model not found (404)",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "o3",
          "valid": false,
          "status_code": 400,
          "error": "Bad request: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "o3-mini",
          "valid": false,
          "status_code": 400,
          "error": "Bad request: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "o3-preview",
          "valid": false,
          "status_code": 404,
          "error": "Model not found (404)",
          "response_preview": null,
          "model_returned": null
        },
        {
          "provider": "openai",
          "model": "gpt-4-turbo",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4-turbo-2024-04-09"
        },
        {
          "provider": "openai",
          "model": "gpt-4-turbo-preview",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4-0125-preview"
        },
        {
          "provider": "openai",
          "model": "gpt-4-turbo-2024-04-09",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4-turbo-2024-04-09"
        },
        {
          "provider": "openai",
          "model": "gpt-3.5-turbo",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-3.5-turbo-0125"
        },
        {
          "provider": "openai",
          "model": "gpt-3.5-turbo-0125",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-3.5-turbo-0125"
        }
      ],
      "valid_models": [
        {
          "provider": "openai",
          "model": "gpt-4o",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-2024-08-06"
        },
        {
          "provider": "openai",
          "model": "gpt-4o-2024-11-20",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-2024-11-20"
        },
        {
          "provider": "openai",
          "model": "gpt-4o-2024-08-06",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-2024-08-06"
        },
        {
          "provider": "openai",
          "model": "gpt-4o-mini",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-mini-2024-07-18"
        },
        {
          "provider": "openai",
          "model": "gpt-4o-mini-2024-07-18",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4o-mini-2024-07-18"
        },
        {
          "provider": "openai",
          "model": "chatgpt-4o-latest",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "chatgpt-4o-latest"
        },
        {
          "provider": "openai",
          "model": "gpt-4-turbo",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4-turbo-2024-04-09"
        },
        {
          "provider": "openai",
          "model": "gpt-4-turbo-preview",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4-0125-preview"
        },
        {
          "provider": "openai",
          "model": "gpt-4-turbo-2024-04-09",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-4-turbo-2024-04-09"
        },
        {
          "provider": "openai",
          "model": "gpt-3.5-turbo",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-3.5-turbo-0125"
        },
        {
          "provider": "openai",
          "model": "gpt-3.5-turbo-0125",
          "valid": true,
          "status_code": 200,
          "error": null,
          "response_preview": "OK",
          "model_returned": "gpt-3.5-turbo-0125"
        }
      ]
    }
  }
}