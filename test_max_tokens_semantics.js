#!/usr/bin/env node

/**
 * Test pour comprendre la s√©mantique de max_tokens
 * Est-ce que max_tokens est :
 * 1. Limite de sortie seulement ?
 * 2. Limite combin√©e entr√©e+sortie ?
 * 3. Limite de sortie mais avec contrainte de contexte total ?
 */

import { GrokClient } from './dist/grok/client.js';

// Cr√©er un client de test (sans initialiser r√©ellement)
console.log('Simulation seulement - pas d\'appel API r√©el\n');

// Simuler diff√©rents sc√©narios
console.log('üß™ Test de s√©mantique de max_tokens\n');

// Sc√©nario 1: Petit contexte, petite limite
console.log('üìä Sc√©nario 1: Petit contexte (1000 tokens), max_tokens=100');
console.log('   - Entr√©e: ~1000 tokens');
console.log('   - max_tokens: 100');
console.log('   - Question: Le mod√®le peut-il r√©pondre ?');

// Sc√©nario 2: Grand contexte, petite limite  
console.log('\nüìä Sc√©nario 2: Grand contexte (8000 tokens), max_tokens=100');
console.log('   - Entr√©e: ~8000 tokens');
console.log('   - max_tokens: 100');
console.log('   - Question: Le mod√®le peut-il r√©pondre ?');

// Sc√©nario 3: Grand contexte, grande limite
console.log('\nüìä Sc√©nario 3: Grand contexte (8000 tokens), max_tokens=8000');
console.log('   - Entr√©e: ~8000 tokens');
console.log('   - max_tokens: 8000');
console.log('   - Question: Le mod√®le peut-il r√©pondre ?');

// Sc√©nario 4: Tr√®s grand contexte, limite raisonnable
console.log('\nüìä Sc√©nario 4: Tr√®s grand contexte (15000 tokens), max_tokens=2000');
console.log('   - Entr√©e: ~15000 tokens');
console.log('   - max_tokens: 2000');
console.log('   - Question: Le mod√®le peut-il r√©pondre ?');

// V√©rifier la documentation des APIs
console.log('\nüìö Documentation des APIs:');
console.log('   - OpenAI: max_tokens = "The maximum number of tokens to generate in the chat completion."');
console.log('   - Anthropic: max_tokens = "The maximum number of tokens to generate before stopping."');
console.log('   - Mistral: max_tokens = "The maximum number of tokens to generate."');

console.log('\nüîç Conclusion probable:');
console.log('   max_tokens limite SEULEMENT la sortie (tokens g√©n√©r√©s).');
console.log('   MAIS: La fen√™tre de contexte totale (entr√©e+sortie) est limit√©e par le mod√®le.');
console.log('   Exemple: GPT-4 a 128K de contexte max.');
console.log('   Si entr√©e = 120K tokens, max_tokens ne peut pas d√©passer 8K (128K - 120K).');

console.log('\n‚ö†Ô∏è  Probl√®me identifi√©:');
console.log('   Si on envoie beaucoup de fichiers (ex: 100K tokens)');
console.log('   Et qu\'on met max_tokens=32K');
console.log('   L\'API va refuser car 100K + 32K > 128K (limite du mod√®le)');
console.log('   Le mod√®le NE PEUT PAS r√©pondre car pas assez d\'espace dans le contexte.');