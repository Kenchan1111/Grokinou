# GPT-5 Token Parameter Question
## 2025-12-07 23:30 - REQUIRES INVESTIGATION

---

## ‚ùì QUESTION CRITIQUE NON R√âSOLUE

**GPT-5 utilise-t-il:**
- **Option A:** `max_tokens` + `temperature` (API standard)
- **Option B:** `max_completion_tokens` + NO temperature (API reasoning)

---

## üîç INDICES CONTRADICTOIRES

### POUR Option A (Standard API)
‚úÖ GPT-5 devrait supporter tools (standard model behavior)
‚úÖ GPT-5 n'est pas market√© comme "reasoning only"
‚úÖ C'est le successor de GPT-4, pas d'o1

### POUR Option B (Reasoning API)
‚ö†Ô∏è Commit f0bd851: "will automatically recognize gpt-5.1 as a reasoning model"
‚ö†Ô∏è Commit 3ed38e7 (Nov 22): "Reasoning models (o1, o3, gpt-5) use max_completion_tokens"
‚ö†Ô∏è Commit 3ead8ad: "GPT-5 returned error: 400 Invalid value for tool_choice"

---

## ü§î HYPOTH√àSE

Il est possible que:
1. **GPT-5 utilise l'API reasoning** (`max_completion_tokens`)
2. **MAIS supporte quand m√™me les tools** (contrairement √† o1/o3)

Cela expliquerait:
- Pourquoi il √©tait dans `isReasoningModel()` (pour tokens)
- Pourquoi l'erreur 400 avec tool_choice (incompatible avec reasoning API?)
- Pourquoi mon fix marche (tools OK maintenant)

---

## üí° SOLUTION PROPOS√âE

Cr√©er DEUX fonctions distinctes:

### 1. `isReasoningModel()` - Pour l'API
```typescript
// Models qui utilisent reasoning API (max_completion_tokens, no temp)
private isReasoningModel(model?: string): boolean {
  const modelName = (model || this.currentModel).toLowerCase();
  return modelName.startsWith('o1') ||
         modelName.startsWith('o3') ||
         modelName.includes('gpt-5');  // Reasoning API
}
```

### 2. `supportsTools()` - Pour tools
```typescript
// Models qui supportent function calling
private supportsTools(model?: string): boolean {
  const modelName = (model || this.currentModel).toLowerCase();
  // o1/o3 do NOT support tools
  // GPT-5 DOES support tools (even if using reasoning API)
  return !(modelName.startsWith('o1') || modelName.startsWith('o3'));
}
```

### Usage
```typescript
// For token parameters
if (isReasoning) {
  requestPayload.max_completion_tokens = adaptiveMaxTokens;
} else {
  requestPayload.max_tokens = adaptiveMaxTokens;
  requestPayload.temperature = 0.7;
}

// For tools
if (tools && tools.length > 0 && this.supportsTools(modelToUse)) {
  requestPayload.tools = formattedTools;
}
```

---

## üß™ TEST REQUIS

Pour v√©rifier, il faut tester GPT-5 et observer:

### Test 1: Avec `max_tokens` (standard)
```bash
curl -X POST https://api.openai.com/v1/chat/completions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "messages": [{"role": "user", "content": "Hello"}],
    "max_tokens": 100,
    "temperature": 0.7
  }'
```

**Si √ßa marche:** GPT-5 = Standard API ‚úÖ

---

### Test 2: Avec `max_completion_tokens` (reasoning)
```bash
curl -X POST https://api.openai.com/v1/chat/completions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "messages": [{"role": "user", "content": "Hello"}],
    "max_completion_tokens": 100
  }'
```

**Si √ßa marche:** GPT-5 = Reasoning API ‚úÖ

---

### Test 3: Avec tools
```bash
curl -X POST https://api.openai.com/v1/chat/completions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-5",
    "messages": [{"role": "user", "content": "What is the weather?"}],
    "tools": [{
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "Get weather",
        "parameters": {"type": "object", "properties": {}}
      }
    }],
    "max_completion_tokens": 100
  }'
```

**Si √ßa marche:** GPT-5 = Reasoning API + Tools ‚úÖ

---

## üìä √âTAT ACTUEL DU CODE

**Apr√®s mon fix (abf394e):**

```typescript
// isReasoningModel() - Pour tokens ET tools
private isReasoningModel(model?: string): boolean {
  return modelName.startsWith('o1') ||
         modelName.startsWith('o3');
  // GPT-5 NOT included
}

// Usage 1: Tools
if (tools && tools.length > 0 && !isReasoning) {
  // GPT-5 will enter here ‚úÖ
}

// Usage 2: Token params
if (isReasoning) {
  requestPayload.max_completion_tokens = ...;
} else {
  requestPayload.max_tokens = ...;
  // GPT-5 will enter here
  // Using max_tokens + temperature
}
```

**Impact:**
- ‚úÖ GPT-5 gets tools (correct)
- ‚ö†Ô∏è GPT-5 uses `max_tokens` (might be wrong if it needs `max_completion_tokens`)

---

## ‚ö†Ô∏è RISQUE POTENTIEL

Si GPT-5 n√©cessite `max_completion_tokens`:
- Mon fix actuel cassera GPT-5 pour les tokens
- Il faudra les deux fonctions (isReasoningModel + supportsTools)

**Sympt√¥me attendu si cass√©:**
- GPT-5 retourne erreur 400 pour `max_tokens`
- Ou ignore `max_tokens` compl√®tement

---

## üéØ ACTION RECOMMAND√âE

**Option 1: Tester maintenant**
```bash
npm start
/model gpt-5
> Write a long story (test max_tokens behavior)
```

Observer:
- GPT-5 r√©pond-il normalement?
- Y a-t-il une erreur 400?
- Respecte-t-il max_tokens?

**Option 2: Impl√©menter les deux fonctions maintenant**
- Safer approach
- Pr√©vient cassure potentielle
- S√©pare les concerns (API vs tools)

---

## üìù D√âCISION √Ä PRENDRE

Tu dois choisir:

**A) Garder le fix actuel**
- Risque: Casse GPT-5 si il n√©cessite reasoning API
- Avantage: Simple, minimal changes

**B) Impl√©menter deux fonctions**
- Risque: Plus complexe
- Avantage: S√©paration correcte (API params vs tools support)

**C) Tester d'abord, puis d√©cider**
- Le plus sage
- N√©cessite acc√®s √† GPT-5 pour tester

---

**Status:** QUESTION OUVERTE - Requires testing or OpenAI docs

**User decision needed:** Quelle approche pr√©f√®res-tu?
